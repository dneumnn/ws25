{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5700f960-7f8d-4368-bc6d-f67c7e862b53",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "Learn to recognize handwritten digits.\n",
    "\n",
    "1. Load MNIST data from OpenML\n",
    "2. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56a12e7-9ccf-4ea4-8968-f4f7ff547948",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installation\n",
    "## !pip install matplotlib\n",
    "## !pip install torch scikit-learn \n",
    "## !pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c6f3d5-103f-4657-a841-708cea3fb98f",
   "metadata": {},
   "source": [
    "## 1 Load MNIST data from OpenML\n",
    "\n",
    "fetch_openml is a scikit-learn function used to download datasets from the OpenML repository, a public platform for machine learning data. https://www.openml.org\n",
    "\n",
    "It can identify datasets by their name and version or by their unique integer data_id. The function returns a Bunch object, similar to a dictionary, containing the dataset's data, target, and description, which can then be used for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9044bca7-c0d0-46e1-9305-eba75f32ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load MNIST from OpenML\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "X_raw, y_raw = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66920bba-0796-4763-a69f-e18024dda35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data   is of type <class 'numpy.ndarray'> with shape (70000, 784)\n",
      "target is of type <class 'numpy.ndarray'> with shape (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"data   is of type\", type(X_raw), \"with shape\", X_raw.shape)\n",
    "print(\"target is of type\", type(y_raw), \"with shape\", y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7797955b-23cf-41ec-a0cc-d1c028dbc9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show image\n",
    "X = X_raw.reshape(-1, 28, 28)  # reshape to images\n",
    "y = y_raw.astype(int)\n",
    "plt.imshow(X[1000], cmap='gray')\n",
    "plt.title(f\"Label: {y[1000]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2a1b9-86cb-42b3-9a48-012cd6848f45",
   "metadata": {},
   "source": [
    "## 2. Normalize the Data and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801f1b91-7ca7-42c3-bbc0-0ece06f2c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 int64\n",
      "0.13092536 0.30844852\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Precision\n",
    "X = X_raw.astype(np.float32)\n",
    "y = y_raw.astype(int)\n",
    "print(X.dtype, y.dtype)\n",
    "\n",
    "# Values between 0 and 1\n",
    "X = X/255.0\n",
    "\n",
    "# Normalize with mean and standard deviation\n",
    "mean = X.mean()\n",
    "std = X.std()\n",
    "print(mean, std)\n",
    "\n",
    "X = (X - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846d221-8a70-4420-8006-32a8ef5b2fed",
   "metadata": {},
   "source": [
    "## 3. Split Data in Train, Validation and Test\n",
    "\n",
    "Use Pytorch dataset for split in train, validation and test set and dataloader for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dc886e-ef29-4c72-8548-863d6ecac7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70000 samples in dataset.\n",
      "There are 49000 samples in train dataset.\n",
      "There are 14000 samples in validation dataset.\n",
      "There are 7000 samples in test dataset.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# DataSet\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = MyDataset(X, y)\n",
    "print(f\"There are {len(dataset)} samples in dataset.\")\n",
    "#print(dataset[0])  # Erstes Sample (Feature-Vektor, Label)\n",
    "\n",
    "# Sizes\n",
    "n_total = len(dataset)\n",
    "n_train = int(0.7 * n_total)  # 70% train\n",
    "n_val   = int(0.2 * n_total)  # 20% validation\n",
    "n_test  = n_total - n_train - n_val  # remaining 10%\n",
    "\n",
    "# Split\n",
    "train_set, val_set, test_set = random_split(dataset, [n_train, n_val, n_test],\n",
    "    generator=torch.Generator().manual_seed(42)  # reproducibility\n",
    ")\n",
    "\n",
    "print(f\"There are {len(train_set)} samples in train dataset.\")\n",
    "print(f\"There are {len(val_set)} samples in validation dataset.\")\n",
    "print(f\"There are {len(test_set)} samples in test dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85055a5f-a43a-4dae-a8c6-22d5ba1c13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e23ab8-e023-4b0d-a12f-882f7464730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataLoader für Mini-Batches\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False) #<-- no shuffle here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d4c23-e96e-40f8-9fe2-9d374510b5a4",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron for Classification \n",
    "\n",
    "![Multi-Layer Perceptron](MLP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f238e3d8-6454-47ca-9420-f969d50c611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),  # Eingabe: 784 -> 128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),    # Zwischenschicht: 128 -> 64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),     # Zwischenschicht: 128 -> 64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),      # Ausgabe: 64 -> 10 Klassen\n",
    "        ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) # Bild (1x28x28) zu Vektor, if input is of shape (batch,28,28)\n",
    "        logits = self.linear_relu_stack(x) # Keine Softmax nötig -> CrossEntropyLoss übernimmt das in PyTorch\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f9c1f-6366-4092-bc31-d174e9483ada",
   "metadata": {},
   "source": [
    "## Detect device and generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645d2047-e49a-4f42-923f-408b4fca1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MNIST(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = MNIST().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066892bd-7974-441b-8005-a95882153813",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2635b97d-6b5c-459a-97d8-9ac13f4de7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242762\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250de478-ea00-42d7-b83a-e6ad1d5bbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3df7d8-67e1-4311-8ab1-60e58c4845b1",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae089a26-aa46-4102-bd59-51bce35cc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6456, Validation Accuracy: 91.86% Saved models/mnist_1_2025-10-19T09-33-34_model_weights.pth\n",
      "Epoch 2, Loss: 0.2598, Validation Accuracy: 93.60% Saved models/mnist_2_2025-10-19T09-33-38_model_weights.pth\n",
      "Epoch 3, Loss: 0.2034, Validation Accuracy: 94.66% Saved models/mnist_3_2025-10-19T09-33-43_model_weights.pth\n",
      "Epoch 4, Loss: 0.1655, Validation Accuracy: 95.60% Saved models/mnist_4_2025-10-19T09-33-48_model_weights.pth\n",
      "Epoch 5, Loss: 0.1398, Validation Accuracy: 95.95% Saved models/mnist_5_2025-10-19T09-33-53_model_weights.pth\n",
      "Epoch 6, Loss: 0.1188, Validation Accuracy: 96.50% Saved models/mnist_6_2025-10-19T09-33-58_model_weights.pth\n",
      "Epoch 7, Loss: 0.1027, Validation Accuracy: 96.76% Saved models/mnist_7_2025-10-19T09-34-03_model_weights.pth\n",
      "Epoch 8, Loss: 0.0893, Validation Accuracy: 97.07% Saved models/mnist_8_2025-10-19T09-34-08_model_weights.pth\n",
      "Epoch 9, Loss: 0.0780, Validation Accuracy: 97.05% Saved models/mnist_9_2025-10-19T09-34-13_model_weights.pth\n",
      "Epoch 10, Loss: 0.0691, Validation Accuracy: 97.04% Saved models/mnist_10_2025-10-19T09-34-18_model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train() # enable training mode (dropout, batchnorm)\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    #save the parameters of model after each epoch\n",
    "    t = datetime.now().replace(microsecond=0).isoformat().replace(\":\",\"-\")\n",
    "    model_filename = f\"models/mnist_{epoch}_{t}_model_weights.pth\"\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss/len(train_loader):.4f}, Validation Accuracy: {100 * correct / total:.2f}% Saved {model_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff5d24b-3c83-4991-a0ed-d2d8e95329ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.10%\n"
     ]
    }
   ],
   "source": [
    "# Use Test Set for Final Check\n",
    "model = MNIST()  # initialize the same model!!\n",
    "\n",
    "# Load the stored parameters with best validation loss\n",
    "model_filename = \"models/mnist_10_2025-10-19T09-34-18_model_weights.pth\"\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs) # batch-size x 10\n",
    "        values, indices = torch.max(outputs, 1) #first max value, second max index --> the number we want to predict\n",
    "        correct += (indices == labels).sum().item() # Anzahl richtiger Paar-Vergleiche \n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21b915-74b8-4edf-b15b-c4a3ab1cca18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
